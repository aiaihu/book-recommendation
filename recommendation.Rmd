
---
Title: "Book Recommendation"
Course ID: "CSDA1040"
Professor: "Mr. Hashmat"
Author: "Group Project: Aimin Amy Hu, Jacob Geeves, Eugene Park"
Date: '2019-May-26'
output:
  html_document: 
    self_contained: no
  pdf_document: default
---



## Getting started
To work with R Markdown, if necessary:

* Install [R](http://www.r-project.org/)
* Install the lastest version of [RStudio](http://rstudio.org/download/) (at time of posting, this is 0.96)
* Install the latest version of the `knitr` package: `install.packages("knitr")`

To run the basic working example that produced this blog post:

* Open R Studio, and go to File - New - R Markdown
* If necessary install `ggplot2` and `lattice` packages: `install.packages("ggplot2"); install.packages("lattice") `
* Paste in the contents of this gist (which contains the R Markdown file used to produce this post) and save the file with an `.rmd` extension
* Please also install.package("pROC")
* Click Knit HTML


## Abstract

The objective for this project is to builde a book recommender system which could suggest books to users based on similarities between books.In other words, it would recommend books that are similar to ones that a user already likes. It would look into similar books from the same genre(perhaps fantasy, science fiction, romance, thriller, mystery etc.). It can even make recommendation based on any variety of common elements such as from the same author.

## Introduction



## Business Objective
The objective for this project is to builde a book recommender system which could suggest books to users based on similarities between books



## Part 1: Data Understanding

### Data Source

The datasets used in this project is hosted by http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/ and below is the link to the dataset.

https://github.com/zygmuntz/goodbooks-10k/releases

Downloaded dataset and saved in local computer.

We assume the dataset come from a site similar to goodreads.com but with more permissive terms of use.
Use below R code to read CSV files from local computer

```{r}
#start by loading some libraries
library(recommenderlab)
library(data.table)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(DT)
library(knitr)
library(grid)
library(gridExtra)
library(corrplot)
library(methods)
library(Matrix)
library(reshape2)

```
```{r}
#set up working directory
setwd("~/York U School/CSDA1040/book-recommendation/Datasets")

# Read 5 CSV files along with header
books=read.csv("books.csv",header = TRUE)
book_tags=read.csv("book_tags.csv", header = TRUE)
ratings= read.csv("ratings.csv", header = TRUE)
tags = read.csv("tags.csv", header = TRUE)
to_read = read.csv("to_read.csv", header =TRUE)

```

### Data Summary

This dataset contains 5 CSV files:book_tags.csv, books.csv, ratings.csv, tags.csv, to_read.csv. We used R read.csv command to read all csv files into data frame.
```{r, eval=FALSE,echo=FALSE}

#check data frame details
str(book_tags)
str(books)
str(ratings)
str(tags)
str(to_read)

```


######to_read:
Contains 912705 observations(rows) and 2 variables(columns). This data set contains user_id and book_id.


#### Ratings.csv
Contains 5976479 observations(rows) and 3 variables(columns). This data set includes all users's ratings of the 10,000 books.

```{r, result='asis', echo=FALSE}
datatable(head(ratings, 10), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(ratings)
```

#### Books.csv
Contains 10000 observations(rows) and 23 variables(columns). This data set contains more information on the books such as author, original_publcation_year, rating,book_id etc.

```{r, result='asis', echo=FALSE}
datatable(head(books,5),  class = "nowrap hover row-border", options = list(dom = 't',scrollX = TRUE, autoWidth=TRUE, columnDefs = list(list(width = '100px', targets = c(6)),list(width = '100px', targets = c(5,6)))))
```
<br>
```{r, echo=FALSE}
glimpse(books)
```

#### Book_tags.csv
Contains 999912 observations(rows) and 3 variables(columns). This data set has all tag_ids users have assigned to that books and corresponding tag_counts.

```{r, result='asis', echo=FALSE}
datatable(head(book_tags, 10), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(book_tags)
```

#### Tags.csv
Contains 34252 observations(rows) and 2 variables(columns). This data set includes the tag_names corresponding to the tag_ids

```{r, result='asis', echo=FALSE}
datatable(sample_n(tags, 5), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(tags)
```

## Part 2: Data Prepartion

To prepare quality dataset for the machine learning, we will need to check our dataset for any duplicated elements, missing values.

### Duplicated elements
We will check if there are duplicated elements in ratings dataset and books dataset. Some users may rating same book for twice. If this is a case, we will then remove the duplicated rows. Also, we will make sure there are not duplicated books in the books dataset. To do this, we will use dplyr. We found there are no duplicated rows in books and book_tags datasets.
```{r}
#loading library for identifying duplicated rows.
library(dplyr)
```
```{r}
#checking if there are duplicated rows

ratings <- ratings %>%
              distinct(user_id, book_id, .keep_all = TRUE)
```
```{r}
books <- books %>%
                distinct(book_id, .keep_all = TRUE)
```

### Missing Values

Using code: colSums(is.na()) to get below display. This tells which variable has how many missing values in this data set.


```{r}

#checking missing value for the dataset
colSums(is.na(book_tags))

```
```{r}
colSums(is.na(books))

```
```{r}
colSums(is.na(ratings))

```
```{r}
colSums(is.na(tags))

```

```{r}
colSums(is.na(to_read))


```
In summary of above results, the missing values are summarized as below list:

Data set  |Variable name             | Missing/NA Values           
----------|--------------------------|-------------------
  books   | isbn13                   | 585                       
  books   | original_publication_year| 21  
          |                          |
There are only missing vaules in books_df. The missing values are isbn(International Standard Book Number) and original_publication_year. These two variables will not be variables used in a recommender system. Therefore, we will not deal these missing values. We can be confident is saying that this dataset contains good quality data.

### Clean data

Before we use the dataset, we will do some data clean to remove unuseful values. In this way, it will make the dataset smaller and make computation faster.

*	Remove variables: books dataset
* This data set contains 585 missing values under variable 'isbn13'. We have variable 'isbn', we assume these two variables are the same, hence, we    will remove variable 'isbn13' from the data frame. 

* This data set contains variable 'best_book_id'. This id number is identical to variable 'goodreads_book_id'. Becasue variable 'goodreads_book_id' is cross referenced in the 'book_tags_df' dataset it will remain while the 'best_book_id' variable is removed.

* This data set contains variable 'work_id'. This variable will be removed as book_id and goodreads_book_id already serve to identify a unique book.


```{r}
books_df <- select(books, -isbn13, -best_book_id)
```
After removed two variables from this dataset, we are haveing 21 variables.

##Part 3: Data Exploration

### Data Exploration:ratings dataset
As we know that the ratings dataset contains user_id, book_id and rating. We use ggplot() and geom()to get visulaztion between these variables.

#### Distribution of ratings
We check distribution of ratings and found:
The most of ratings are between 3-5 and less than 500,000 ratings are in 1 and 2.

```{r}
library(ggplot2)
ratings %>% 
  ggplot(aes(x = rating, fill = factor(rating))) +
  geom_bar(color = "grey10") + scale_fill_brewer(palette = "Dark2") + guides(fill = FALSE)

```
#### Number of ratings per book
We want to check the distribution of the number of ratings for each book. Most of books has total of ratings below 1000.

```{r}
#group by book_id,then do the plot
ratings %>% 
  group_by(book_id) %>% 
  summarize(number_of_ratings_per_book = n()) %>%
  ggplot(aes(number_of_ratings_per_book)) + 
  geom_bar(fill = "green", color = "grey20",width = 1) +
  coord_cartesian(c(100, 3000))
  
```




####Number of ratings per user
People are pretty active for the ratings. Most of people have number of rating between 75 - 150 times.
```{r}
ratings %>% 
  group_by(user_id) %>% 
  summarize(number_of_ratings_per_user = n()) %>% 
  ggplot(aes(number_of_ratings_per_user)) + 
  geom_bar(fill = "cadetblue3", color = "grey20") + coord_cartesian(c(3, 200))
```

####Distribution of mean book ratings
What we have seen from below plot is the most of books have mean between 3.5- 5, this tells us that most of books get postive ratings.
```{r}
#group by book_id and get mean of rating for each book_id. We get a new dataset with column mean_perbook

rating_perbook<-ratings %>%
        group_by(book_id) %>%
        mutate(mean_perbook = mean(rating, na.rm=T))
        
```

```{r}
ggplot(rating_perbook, aes(mean_perbook))+geom_histogram(fill = "orange", color = "grey20", bins = 30) + coord_cartesian(c(1,5))
```

####Distribution of mean user ratings
From below plot, we saw that more people tend to give ratings higher than 3.5. Some of them have tendence to give highest rating 5, and another concentration area is around rating 4.

```{r}
ratings %>% 
  group_by(user_id) %>% 
  summarize(mean_per_user_rating = mean(rating)) %>% 
  ggplot(aes(mean_per_user_rating)) +
  geom_histogram(fill = "red", color = "grey20", bins =30)
```
### Data Exploration:books dataset

The books dataset contains 21 variables after our data cleaning. We will explore some variables in this dataset to see how they are related to the ratings.

```{r}
# list of varialbe names in the books dataset
names(books)
```
We see there are variables called language_code and authors. First, we will check how laugange related to the books. We uderstood that the dataset is from an English speaking website and assume that the most of books are English.

####Languages

From below plots, we see there are less than 1000 books are non-English.

```{r}
#import some libraries
library(grid)
library(ggplot2)
library(lattice)

```
```{r}
#language: English(this will include en-US, en-GB,eng,en-CA)
p_english <- books %>% 
  mutate(language = factor(language_code)) %>% 
  group_by(language) %>% 
  summarize(number_of_books = n()) %>% 
  arrange(-number_of_books) %>% 
  ggplot(aes(reorder(language, number_of_books), number_of_books, fill = reorder(language, number_of_books))) +
  geom_bar(stat = "identity", color = "grey20", size = 0.5) + coord_flip() +
  labs(x = "language", title = "English") + guides(fill = FALSE)

P_non_english <- books %>% 
  mutate(language = factor(language_code)) %>% 
  filter(!language %in% c("en-US", "en-GB", "eng", "en-CA", "")) %>% 
  group_by(language) %>% 
  summarize(number_of_books = n()) %>% 
  arrange(-number_of_books) %>% 
  ggplot(aes(reorder(language, number_of_books), number_of_books, fill = reorder(language, number_of_books))) +
  geom_bar(stat = "identity", color = "grey20", size = 0.5) + coord_flip() +
  labs(x = "", title = "Non-English") + guides(fill = FALSE)

grid.arrange(p_english,P_non_english, ncol=2)

```
####Authors
We see from below plot, there are a few authors with lower rating below 3,which may indicate that rating is high or low not related to author.
```{r}
books %>% 
  group_by(authors, average_rating) %>% 
  summarize(mean_per_authors_rating = mean(average_rating)) %>% 
  ggplot(aes(mean_per_authors_rating)) +
  geom_histogram(fill = "red", color = "grey20", bins =30)
```
#### Top 10 books in average_rating  
We rank the top 10 rated books according to their average_rating. The Complete Calvin and Hobbes has the highest average_rating at 4.82, it's so close to 5. With 28900 ratings_count, we see almose every one gives this book high rating.  
```{r}
#import library
library(DT)
library(dplyr)
```
```{r}
#use arrange()to sort variable avaerage_rating, then get the top 10 books with title, ratings_count, average_rating and authors
  books %>% 
  arrange(-average_rating) %>% 
  top_n(10,wt = average_rating) %>% 
  select(title, ratings_count, average_rating, authors) %>% 
  datatable(class = "nowrap hover row-border", escape = FALSE, options = list(dom = 't',scrollX = TRUE, autoWidth = TRUE))
```
#### Top 10 books in ratings_count  
We rank the top 10 books according to their ratings_count. We saw some books on the list but their average_rating is less than mean of average_rating. This tells us a book is popular to be rated, but it doesn't mean that this book has higher average_rating.

```{r}
#use arrange()to sort variable ratings_count, then get the top 10 books with title, ratings_count, average_rating and authors
  books %>% 
  arrange(-ratings_count) %>% 
  top_n(10,wt = ratings_count) %>% 
  select(title, ratings_count, average_rating, authors) %>% 
  datatable(class = "nowrap hover row-border", escape = FALSE, options = list(dom = 't',scrollX = TRUE, autoWidth = TRUE))
```
```{r}
# mean of average_rating
mean(books$average_rating)
```
