
---
Title: "Book Recommendation"
Course ID: "CSDA1040"
Professor: "Mr. Hashmat"
Author: "Group Project: Aimin Amy Hu, Jacob Geeves, Eugene Park"
Date: '2019-May-26'
output:
  html_document: 
    self_contained: no
  pdf_document: default
---


  
# Book Recommendation System
*By  Aimin Amy Hu, Jacob Geeves, Eugene Park*   

## Abstract

To build a book recommender system which could suggest books to users based on what other book lovers who have read and rated in the past.In other words, it would recommend books that are similar to ones that a user already likes. It would look into similar books from the same genre(perhaps fantasy, science fiction, romance, thriller, mystery etc.). It can even make recommendation based on any variety of common elements such as from the same author.

## Introduction
With techlogy rapidly update every day, online shopping, social media, YouTube and Netflix and many other websites are becoming  hoter and hoter every day. When you shopping on Amazon, you properly noted there were some products recommendation below the products which you have just bought.Have you ever bought anything from their recommended products? Did the recommended product ratings affect your buying decision? How did the recommend this product to you? Instead of discuss recommendation for shopping items online, we will discuss  recommendation system for books in this report.

## Business Objective
The objective for this project is to build a book User_based Collaborative Filtering recommender system which could suggest books to users based on what other book lovers with similar profiles have liked books in the past.

## Research Questions:

* Q1: Does book's rating affect book's popularity?
* Q2: How to predict user's rating or preferences for a given book?
* Q3: How variables provide a predictive estimate of the likely rating for a new book ?

## Assumptions

* We assume the datasets come from a site similar to goodreads.com but with more permissive terms of use.
* We cannot see users' profiles such as their culture backgroud, income, edcuation backgroud,age etc. from the dataset, but we assume that the dataset has widely users from different level, backgroud from North America(this dataset comes from a US website).
* We assume lack of users profiles' information will potentially reduce the recommender's accuracy. If this will be used for a online shopping book store, we strongly recommend to take consideration of the users' profiles.



## Part 1: Data Understanding

### Data Source

The datasets used in this project is hosted by http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/ and below is the link to the dataset.

https://github.com/zygmuntz/goodbooks-10k/releases

Downloaded dataset and saved in local computer.

Use below R code to read CSV files from local computer

```{r results='hide', message=FALSE, warning=FALSE, results ='hide'}
#start by loading some libraries
library(recommenderlab)
library(data.table)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(DT)
library(knitr)
library(grid)
library(gridExtra)
library(corrplot)
library(methods)
library(Matrix)
library(reshape2)

```
```{r}
#set up working directory - this will set the working directory to the same folder as your R studio RMD file - ensure that the CSVs outlined below are also in this folder
set_wd <- function() {
library(rstudioapi) # make sure you have it installed
current_path <- getActiveDocumentContext()$path 
setwd(dirname(current_path ))
print( getwd() )
}


# Read 4 CSV files along with header
books <- fread("books.csv",header = TRUE)
book_tags <- fread("book_tags.csv", header = TRUE)
ratings <- fread("ratings.csv", header = TRUE)
tags <- fread("tags.csv", header = TRUE)

```
```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

### Data Summary

This dataset contains 4 CSV files:book_tags.csv, books.csv, ratings.csv, tags.csv, We used R read.csv command to read all csv files into data frame.

#### ratings.csv
Contains 5976479 observations(rows) and 3 variables(columns). This dataset includes all users's ratings of the 10,000 books.

```{r, result='asis', echo=FALSE}
datatable(head(ratings, 10), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(ratings)
```

#### books.csv
Contains 10000 observations(rows) and 23 variables(columns). This data set contains more information on the books such as author, original_publcation_year, rating,book_id etc.

```{r, result='asis', echo=FALSE,message=FALSE, warning=FALSE}
datatable(head(books,5),  class = "nowrap hover row-border", options = list(dom = 't',scrollX = TRUE, autoWidth=TRUE, columnDefs = list(list(width = '100px', targets = c(6)),list(width = '100px', targets = c(5,6)))))
```
<br>
```{r, echo=FALSE}
glimpse(books)
```

#### book_tags.csv
Contains 999912 observations(rows) and 3 variables(columns). This data set has all tag_ids users have assigned to that books and corresponding tag_counts. We will not need this dataset in this project.

```{r, result='asis', echo=FALSE}
datatable(head(book_tags, 10), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(book_tags)
```

#### tags.csv
Contains 34252 observations(rows) and 2 variables(columns). This data set includes the tag_names corresponding to the tag_ids. However, there are many unclear information there. We will not need this dataset in this project.

```{r, result='asis', echo=FALSE, warning=FALSE, message=FALSE}
datatable(sample_n(tags, 5), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(tags)
```

## Part 2: Data Prepartion

To prepare quality dataset for the machine learning, we will need to check our dataset for any duplicated elements, missing values.

### Step 1: Duplicated elements
We will check if there are duplicated elements in ratings dataset and books dataset. Some users may rating same book for twice. If this is a case, we will then remove the duplicated rows. Also, we will make sure there are not duplicated books in the books dataset. To do this, we will use dplyr. We found there are no duplicated rows in books and book_tags datasets.
```{r}
#loading library for identifying duplicated rows.
library(dplyr)
```
```{r}
#checking if there are duplicated rows and removed it. distinct() keep only unique/distinct rows from a data frame.
ratings <- ratings %>% distinct(user_id,book_id, .keep_all = TRUE)
```       
```{r}
cat('Number of rows after removed duplicated rows if there are: ', nrow(ratings))          
```
```{r}
books <- books %>%
                distinct(book_id, .keep_all = TRUE)
cat('Number of rows after removed duplicated rows if there are: ', nrow(books)) 
```

### Step 2: Missing values

Using code: colSums(is.na()) to get below display. This tells which variable has how many missing values in this data set.


```{r}

#checking missing value for the dataset
colSums(is.na(book_tags))

```
```{r}
colSums(is.na(books))

```
```{r}
colSums(is.na(ratings))

```
```{r}
colSums(is.na(tags))

```

In summary of above results, the missing values are summarized as below list:

Data set  |Variable name             | Missing/NA Values           
----------|--------------------------|-------------------
  books   | isbn13                   | 585                       
  books   | original_publication_year| 21  
          |                          |                   
There are only missing vaules in books dataset. The missing values are isbn(International Standard Book Number) and original_publication_year. These two variables will not be variables used in a recommender system. Therefore, we will not deal these missing values. We can be confident is saying that this dataset contains good quality of data.

### Step 3:Clean data

Before we use the dataset, we will do some data clean to remove unuseful values. In this way, it will make the dataset smaller and make computation faster.

*	Remove variables from books dataset
* This data set contains 585 missing values under variable 'isbn13'. We have variable 'isbn', we assume these two variables are the same, hence, we    will remove variable 'isbn13' from the data frame. 

* This data set contains variable 'best_book_id'. This id number is identical to variable 'goodreads_book_id'. Becasue variable 'goodreads_book_id' is cross referenced in the 'book_tags_df' dataset it will remain while the 'best_book_id' variable is removed.

* This data set contains variable 'work_id'. This variable will be removed as book_id and goodreads_book_id already serve to identify a unique book.


```{r}
books <- select(books, -c("isbn13", "best_book_id"))

```

After removed two variables from this dataset, we are haveing 21 variables.

##Part 3: Data Exploration


### Ratings dataset

####Select a subset dataset
Our ratings dataset contains about 6 million rows, it is huge dataset for the analysis and also takes a lot of memory space. In order to have faster computation speed, we decided to suset the ratings dataset with sample fraction at 25% . As it is a huge dataset (still about 1.5million rows), we believe this subset will not bring any bias for the analysis.

```{r}
# with 25% of users(for FYI only, I have tried 40%, it's still very slow for computation of matrix, therefore, we decided to use 25% instead )
set.seed(1)
user_fraction <- 0.25
users <- unique(ratings$user_id)
```

```{r}
sample_users <- sample(users, round(user_fraction * length(users)))
```

```{r}
cat('Number of ratings (before): ', nrow(ratings))
```
```{r}
ratings <- filter(ratings,user_id %in% sample_users)

cat('Number of ratings (after): ', nrow(ratings))
```
As we know that the ratings dataset contains user_id, book_id and rating. We use ggplot() and geom()to get visulaztion between these variables.


#### Distribution of ratings
After we checked distribution of ratings and found:
The most of ratings are between 3-5 and about 100,000 ratings are in 1 and 2.

```{r}
library(ggplot2)
ratings %>% 
  ggplot(aes(x = rating, fill = factor(rating))) +
  geom_bar(color = "grey10") + scale_fill_brewer(palette = "Dark2") + guides(fill = FALSE)

```


#### Number of ratings per book
We want to check the distribution of the number of ratings for each book. Most of books has total number of ratings below 1000.

```{r}
#group by book_id,then do the plot
ratings %>% 
  group_by(book_id) %>% 
  summarize(number_of_ratings_per_book = n()) %>%
  ggplot(aes(number_of_ratings_per_book)) + 
  geom_bar(fill = "green", color = "grey20",width = 1) +
  coord_cartesian(c(100, 3000))
  
```

####Number of ratings per user
People are pretty active for the ratings. Most of people have number of rating between 75 - 150 times.
```{r}
ratings %>% 
  group_by(user_id) %>% 
  summarize(number_of_ratings_per_user = n()) %>% 
  ggplot(aes(number_of_ratings_per_user)) + 
  geom_bar(fill = "cadetblue3", color = "grey20") + coord_cartesian(c(3, 200))
```

####Distribution of mean ratings for each book
What we have seen from below plot is the most of books have mean between 3.5- 5, this tells us that most of books get postive ratings.
```{r}
#group by book_id and get mean of rating for each book_id. We get a new dataset with column mean_perbook

rating_perbook<-ratings %>%
        group_by(book_id) %>%
        mutate(mean_perbook = mean(rating, na.rm=T))
        
```

```{r}
ggplot(rating_perbook, aes(mean_perbook))+geom_histogram(fill = "orange", color = "grey20", bins = 30) + coord_cartesian(c(1,5))
```

####Distribution of mean user ratings
From below plot, we saw that more people tend to give ratings higher than 3.5. Some of them have tendence to give highest rating 5, and another concentration area is around rating 4.

```{r}
ratings %>% 
  group_by(user_id) %>% 
  summarize(mean_per_user_rating = mean(rating)) %>% 
  ggplot(aes(mean_per_user_rating)) +
  geom_histogram(fill = "red", color = "grey20", bins =30)
```

####Does rater relate to rating?
From below plot, we see a possiblity of rating differently between frequent users and less frequent users.

```{r, message=FALSE, warning=FALSE}
ratings %>%
  group_by(user_id) %>%
  summarize(mean_rating =mean(rating), number_of_rated_books =n())%>%
  ggplot(aes(number_of_rated_books, mean_rating))+stat_bin_hex(bins =50) +scale_fill_distiller(palette ="Spectral")+
  stat_smooth(method = "lm", color = "orchid", size = 2)+
  scale_color_gradient()+
  theme_bw()

```


### Books dataset

The books dataset contains 21 variables after our data cleaning. We will explore some variables in this dataset to see how they are related to the ratings.

```{r}
# list of varialbe names in the books dataset
names(books)
```
We see there are variables called language_code and authors. First, we will check how laugange related to the books. We uderstood that the dataset is from an English speaking website and assume that the most of books are English.

####Languages

From below plots, we see majority of books are English books.

```{r}
#import some libraries
library(grid)
library(ggplot2)
library(lattice)

```
```{r}
#language: English(this will include en-US, en-GB,eng,en-CA)
p_english <- books %>% 
  mutate(language = factor(language_code)) %>% 
  group_by(language) %>% 
  summarize(number_of_books = n()) %>% 
  arrange(-number_of_books) %>% 
  ggplot(aes(reorder(language, number_of_books), number_of_books, fill = reorder(language, number_of_books))) +
  geom_bar(stat = "identity", color = "grey20", size = 0.5) + coord_flip() +
  labs(x = "language", title = "English") + guides(fill = FALSE)

P_non_english <- books %>% 
  mutate(language = factor(language_code)) %>% 
  filter(!language %in% c("en-US", "en-GB", "eng", "en-CA", "")) %>% 
  group_by(language) %>% 
  summarize(number_of_books = n()) %>% 
  arrange(-number_of_books) %>% 
  ggplot(aes(reorder(language, number_of_books), number_of_books, fill = reorder(language, number_of_books))) +
  geom_bar(stat = "identity", color = "grey20", size = 0.5) + coord_flip() +
  labs(x = "", title = "Non-English") + guides(fill = FALSE)

grid.arrange(p_english,P_non_english, ncol=2)

```


####Authors
We see from below plot, there are a few authors with lower rating below 3,which may indicate that rating is high or low not related to authors.
```{r}
books %>% 
  group_by(authors, average_rating) %>% 
  summarize(mean_per_authors_rating = mean(average_rating)) %>% 
  ggplot(aes(mean_per_authors_rating)) +
  geom_histogram(fill = "red", color = "grey20", bins =30)

```


However,we saw number of authors is a matter of the rating from below plot.The more authors a book has the higher average rating is. 

```{r}
books_author <- books %>% 
  group_by(book_id) %>% 
  mutate(number_of_authors = length(str_split(authors, ",")[[1]]))

books_author %>% filter(number_of_authors <= 10) %>% 
  ggplot(aes(number_of_authors, average_rating)) + stat_bin_hex(bins = 50) + scale_fill_distiller(palette = "Spectral") +
  stat_smooth(method = "lm", size = 2, color = "orchid", se = FALSE)+
  scale_color_gradient()+
  theme_bw()

```


#### Does average_rating relate to ratings_count?
From below plot, we see there are only in a small extent, average_rating is higher and number of ratings_count is higher.

```{r}
ggplot(books,aes(x=ratings_count, y=average_rating))+
  geom_point(aes(color = books_count)) +
  stat_smooth(method = "lm", color = "orchid", size = 2)+
  scale_color_gradient()+
  theme_bw()
  
       
```


#### Top 10 books in average_rating  
We rank the top 10 rated books according to their average_rating. The Complete Calvin and Hobbes has the highest average_rating at 4.82, it's so close to 5. With 28900 ratings_count, we see almost every one gives this book the highest rating.  
```{r}
#import library
library(DT)
library(dplyr)
```
```{r}
#use arrange()to sort variable avaerage_rating, then get the top 10 books with title, ratings_count, average_rating and authors
  books %>% 
  arrange(-average_rating) %>% 
  top_n(10,wt = average_rating) %>% 
  select(title, ratings_count, average_rating, authors) %>% 
  datatable(class = "nowrap hover row-border", escape = FALSE, options = list(dom = 't',scrollX = TRUE, autoWidth = TRUE))

```


#### Top 10 books in ratings_count  
We rank the top 10 books according to their ratings_count. We saw some books on the list but their average_rating is less than mean of average_rating. This tells us a book is popular to be rated, but it doesn't mean that this book has higher average_rating.


```{r}
#use arrange()to sort variable ratings_count, then get the top 10 books with title, ratings_count, average_rating and authors
  books %>% 
  arrange(-ratings_count) %>% 
  top_n(10,wt = ratings_count) %>% 
  select(title, ratings_count, average_rating, authors) %>% 
  datatable(class = "nowrap hover row-border", escape = FALSE, options = list(dom = 't',scrollX = TRUE, autoWidth = TRUE))
```
```{r}
# mean of average_rating
mean(books$average_rating)
```

### Correlation Matrix

A correlation matrix is a table showing correlation coefficients between variables. The books contains many variables. Some of variables may not have correlation or weak correlation with other variables. Use corrplot() function to see Visualization of Correlation Matrix.

We see some correlations from below correlation martrix plot.

* Variable ratings_count has positive 1 correlation with variable work_ratings_count. Does this mean that they are same vaules but just called different variable name? We are not sure about this as the discrepation about the dataset did not specify it.

* Variable work_text_reviews_count has positive 0.8 correlation with ratings_count and work_ratings_count.This total makes sense, when people write text review, will more likely to rate it.

* Variable books_count has positive correlation with variable work_text_reviews_count, ratings_count and work_ratings_count; this variable also has strong negative correlation with variable original_publication_year, this does make sense as the original_publication_year increases, the books_count decreases. Variable books_count also has negative correlation with average_rating, but not strong, is just about -0.1.


```{r}
#correlation matrix, select variables with numeric vaules
books_subset <- books %>% 
  select(one_of(c("books_count","original_publication_year","ratings_count", "work_ratings_count", "work_text_reviews_count", "average_rating"))) %>% 
  as.matrix()
corrplot(cor(books_subset,use = 'pairwise.complete.obs'), type = "upper", order = "hclust")
        
```


###Conclusion
We have explored ratings dataset and books dataset and identified some variables that affect on book ratings, this will help us to recommend a book. However,these dataset does not include many other aspects such as user's age group, income, education, culture backgroud etc. We are unclear how these aspects influnce on the book ratings.


## Part 4: Build Model - Collaborative Filtering

Collaborative filtering is a method that uses data from other users to make its prediction. 

A recommendation system is a type of information filter, which can learn users’ interests and hobbies according to their profile or historical behaviors, and then predict their ratings or preferences for a given item. Recommendation algorithms generally make recommendations based on two types of collaborative filtering algorithms; User-based collaborative or item-based collaborative filtering. 

**User-based collaborative filtering systems**: A user-based recommendation engine recommends products such as movies or online shopping items, books based on what other users with similar profiles have watched/liked or bought in the past. 


**Item-based collaborative filtering systems**: An item-based recommender would make recommendations based on similarities bewtween products. It would recommend the products that are similar to ones that you already like. For example, if a user readed  "Little Women" and liked it so this user given it rating 5 stars. A item-based collaborative filtering system would then look into similar books from the same genre(perhaps romance,true love, womenhood or based on similar storyline) and then recommend to the user similar books based on the preference the user indicated when he/she gave "Little Women" rating. An item-based collaborative filtering system can also make recommendations based on any other variety of common elements such as from the same author.

In this project, we will implement User-based collaborative filtering systems. Below are steps for useing Recommenderlab in R.


###Step 1: Create ratings matrix

####Create a sample matrix for understanding

To restructure our train dataset by create a ratings matrix with rows as user_id and columns as book_id. Here is example to understand it.
user_id: 6,7,8
book_id:1,2,3,4,5

```{r, echo=FALSE}
#Create ratings matrix with rows as user_id and columns as book_id.
matrix(data = c(NA, 5, 4, NA, NA, 2, 1, NA, 4, NA, NA, NA, 3, NA, 3), nrow = 3, ncol = 5, byrow = TRUE, dimnames = list(user_id = 6:8, book_id = 1:5))

```

####Create ratings dataset matrix with rows as user_id and columns as book_id

```{r}
#creat a dimension_names list
dimension_names <- list(user_id = sort(unique(ratings$user_id)), book_id = sort(unique(ratings$book_id)))
```

```{r, message = FALSE,warning=FALSE}
library(tidyverse)

```

```{r}
#Spread a key-value pair across multiple columns.spread() takes two columns (key & value), and spreads into multiple columns: it makes “long” data wider.(will take several minutes due to the large dataset)
ratingmat <- spread(select(ratings, book_id, user_id, rating), book_id, rating) %>%
  select(-user_id)
```
```{r}
#Create dataset matrix with rows as user_id and columns as book_id

ratingmat = as.matrix(ratingmat)
```

```{r}
# check the class ratingmat
class(ratingmat)

```

```{r}
#set the dimnames of matrix
dimnames(ratingmat)<-dimension_names
ratingmat[1:5, 1:5]
```
```{r}
#check dimension of ratingmat matrix
dim(ratingmat)

```


###Step 2:Covert ratings matrix to real matrix

In above, we see there are the most of the values in the rating matrix are missing(null values), because every user just rated a few of the 10000 books. We will replace the null values with "0" in the matrix, this allows us to represent this matrix as "sparse matrix".


```{r}
# save ratingmat to a new dataset and replacing null values dataset with 0(will take several minutes)
ratingmat_new <- ratingmat
ratingmat_new[is.na(ratingmat)] <- 0


```
```{r}
#sparseMatrix
sparse_ratings <- as(ratingmat_new, "sparseMatrix") 

#remove ratingmat_new as we don't need it anymore
rm(ratingmat_new)
gc()
```


Conver ratings matrix into a dense matrix by removing the zero's

```{r}
#Convert ratings matrix into real matrix which makes it dense.
real_ratings =new("realRatingMatrix", data=sparse_ratings)
real_ratings[1:5,1:5]
dim(real_ratings)
```



###Step 3: Useing recommenderlab
The recommendation package in R that we will use is recommenderlab. It provides us a User Based Collaborative Filtering (UBCF) model. For similarity among user ratings, we have a choice to calculate similarity according to the following methods:

* Jaccard similarity
* Cosine similarity
* Pearson similarity

#### Create Recommender Model

The parameters are UBCF and Cosine similarity. We take 5 nearest neighbours.

```{r}

#Create Recommender Model. The parameters are UBCF and "pearson" similarity. We take 5 nearest neighbours
rec_mod = Recommender(real_ratings, method = "UBCF", param=list(method="pearson",nn=5)) 

```
#### Predictions of ratings and recommendation

We have built our model, now we can start to do predictions by call predict(). This will pass the model, the ratings for the user that you wish to predict ratings for and a parameter which is to tell the function that we want to get predicted ratings back.

Let's predict the 20th user entry in the real_ratings dataset.We want to look at the top 5 books that the user would give rating for . For the convenience, we call this user "Galileo"
```{r}
#Obtain top 5 ratings from 20th user(Galileo) entry in dataset. type ="ratings" is a parameter to tell the function that we want to get predicted ratings back.
Top_5_pred = predict(rec_mod, real_ratings[20], type="ratings")

# Convert the list to data frame

Top_5_df =as(Top_5_pred, "data.frame")
```

```{r}
head(Top_5_df)
```

```{r, message=FALSE, warning=FALSE}
# arrange by rating and left_join with books dataset to get book title, author and book_id
Top_5_df %>%
  arrange(-rating) %>% .[1:5,] %>%
  mutate(book_id = as.numeric(as.character(item))) %>%
  left_join(select(books,authors,title, book_id),by ="book_id") %>%
  select(-item) %>%
  datatable(class = "nowrap hover row-border",escape=FALSE, options = list(dom = 't',scrollx = TRUE, autoWidth = TRUE))

```
Based on other users who are similar to user "Galileo"have rated these books, we predected ratings for these 5 books that user "Galileo" will probably give.

After we got predected ratings for books from the user, we can now based on the propable ratings to recommend books for them.



###Step 4: Evaluating the predictions

####Create evaluation scheme

Recommenderlab offers the possibility to easily evaluate and compare algorithms for recommendation systems.
evaluationScheme() is to create an evaluationScheme object from a data set. The scheme can be a simple split into training and test data.
method: split
k =1 for split
k: 1 fold crossvalidation
given = -1:means all-but-1 evaluation
goodRating = 4: all items with actual user rating of greater or equal 4 are considered positives in the evaluation process.
We train a UBCF model by using a small training dataset.

We split the first 2000 users in real_ratings dataset into 90/10 (known/unknown)

```{r}
# create 90/10 split (known/unknown) for the first 2000 users in real_ratings
scheme <- evaluationScheme(real_ratings[1:2000,], method = "split", train = .9, k = 1, given = -1, goodRating = 4)
scheme
```
#### Crate training dataset,test dataset(known/unknown)

```{r}
#training set
tr_data <- getData(scheme,"train")
tr_data
```
```{r}
#test_kn set
test_kn <- getData(scheme, "known")
test_kn
```

```{r}
#test_unkn set
test_unkn <- getData(scheme,"unknown")
test_unkn

```

#### List all the Algorithms 
We can list all the algorithms we want to compare.
nn: the number of most similar users which are used to calculate the predictions
algorithm ="RANDOM": randomly predicts a rating for each user

```{r}
algorithms <- list("random" = list(name = "RANDOM", param = NULL),
                   "UBCF_5" = list(name = "UBCF", param = list(method ="pearson",nn = 5)),
                   "UBCF_10" = list(name = "UBCF", param = list(method="pearson",nn = 10)),
                   "UBCF_20" = list(name = "UBCF", param = list(method="pearson",nn = 20)),                 
                   "UBCF_40" = list(name = "UBCF", param = list(method="pearson",nn = 40))
                   )

```
####Evaluate all results: run algorithms and predict
We use evaluate() function to evaluate the alogrithms with the given scheme. Let's predict it.

```{r}
# run alogrithms and predict(it takes about 6 minutes due to 5 algorithms)
eva_results <- evaluate(scheme, algorithms,type ="ratings")
```

#### Visualize RMSE,MSE and MAE for eva_results

* RMSE: Root Mean Square Error. It tells you how concentrated the data is around the line of best fit.
In order to plot RMSE, we will need to re-structure eva_results.

* MSE: Mean Squared Error. MSE puts more weight into penalizing larger errors, so MSE is more useful when large errors are undesirable.

* MAE: Mean Absolute Error.It is a measure of deviation of recommendation from user’s actual value.

```{r}

plot(eva_results)

```
The lower the MAE and RMSE, the more accurately the recommendation engine predicts user ratings. These metrics are good to use when the recommendations are based on predicting rating or number of transactions. They give us a sense of how accurate our prediction ratings are, and in turn how accurate our recommendations are.

In above, we see user_based CF algrothms preform better prediction than RANDOM, but the UBCF model takes much longer time than RANDOM model. We sacrifice time to get better prediction. Another fact is RMSE increases slightly when increasing number of nearest neighbours nn. 


####create user-based CF recommender using training data

```{r}
#create a user-based CF recommender using training data
ub_rcmnd <- Recommender(tr_data,"UBCF",param=list(method="pearson", nn =10))
ub_rcmnd

```
```{r}
ubc_rcmnd <- Recommender(tr_data,"UBCF",param=list(method="cosine", nn =10))
ubc_rcmnd 
```

####Create predictions for the test users using know ratings
```{r}
#create predictions for the test data using known ratings
tub_pre<- predict(ub_rcmnd, test_kn, type = "ratings")
tub_pre

tubc_pre <- predict(ubc_rcmnd, test_kn, type = "ratings")
tubc_pre
```
####Evaluate recommendations on "unknown" ratings

```{r}
# UBCF Pearson

tub_ac <-calcPredictionAccuracy(tub_pre, test_unkn)
head(tub_ac)
```
```{r}
#UBCF Cosine
tubc_ac <-calcPredictionAccuracy(tubc_pre, test_unkn)
head(tubc_ac)
```
We see from above evaluation, RMSE for both are just around 0.82 which is a small number, but the Pearson has the smallest number.Hence, we will use Pearson model. We are confident to say that our model is fit to this dataset for the recommendations.

####Compare predictions with real "unknown" ratings

```{r}
as(test_unkn, "matrix")[1:15, 60:70]
```
```{r}
as(tub_pre, "matrix")[1:15, 60:70]
```

From above, we guess the accuracy rate might not be high. Does this due to a small dataset that we are using? I am not quite sure as our RMSE was low.

####Create recommendations topNList with n=5  for a user
```{r}
top_n_p <-predict(ub_rcmnd,real_ratings[20],n=5)

top_n_p
```
```{r}
as(top_n_p, "list")
```

#### Create a "new" user ratings and recommend next book
Create ratings matrix with rows as user_id and columns as book_id


```{r}
#Create initial empty predictions matrix.

m <- matrix(sample(c(NA,0:5),nrow(books), replace=TRUE, prob=c(.6,rep(.3/6,6))),
	nrow=1, nrow(books), dimnames = list(
	    user_id =paste(1:1),
	    book_id =paste(1:nrow(books))
    ))
dim(m)

```




```{r}
# coerce into a realRatingMAtrix
ratings.new <- as(m, "realRatingMatrix")
dim(ratings.new)
```


####Recommend next 5 books for this new user

```{r}
rec_book <-predict(ub_rcmnd,ratings.new, n=5)
rec_num = as(rec_book, "list")
rec_num
```
## Part 5: Shiny App

In order to have a real book recommender, we built an book recommendation app. We used the UBCF Collaborative Filtering system to recommend the top 5 books for an user who rates at least books which we give on the app. All books will be randomly given to the user to rate on the app. We need user to rate at least 5 books to get the recommendations. Ideally, the more books user rated, the better recommendation accuracy is. However, due to ShinyApp.io limited space (1GB) for an instance, we only give 20 books to rate.

We deloyed our app on [Shinyapps.io](https://amy-hu-zhao-2001.shinyapps.io/book_recommend_shiny_app/)

Shiny App code on [github](https://github.com/aiaihu/book_recommend_shiny_app)

Due to the limited space for the instance, we can only use a small ratings dataset when we built the recommendation model for the app. 


##Deployment Discussion

* Based on RMSE number, UBCF model is the model gives better accuracy. We can use this model to recommend books, movies,shows or some other items for online shopping. However, this model takes longer time than RANDOM. When you have a large dataset, you may need to take the time and prediction accuracy into your consideration.

* As one user can rate many books or one book can have many user to rate it, therefore, when we do the dataset split based on user_id, it could bring bias into the train and test dataset.

* ShinyApps.io only offers 1GB for an instance, we are unable to ask user to rate more than 50 books at a time as it crashes sometimes. To avoid the crash on the app, we only give 20 books for a user to rate at a time. Ideally,user rates more books and the recommendation model perfermances better accuracy. We would suggest to have a big instance for the app and load more books for user to rate.


* We would suggest future analysis to combine with tags dataset. This will get genre information.

* We would also suggest to get more information about user profiles such as age, education background, culture background etc. to do more deep analying as there are many factors in people's reading taste.

## Project Codes

All project codes and dataset are on [github](https://github.com/aiaihu/book-recommendation)



