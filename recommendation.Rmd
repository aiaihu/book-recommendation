
---
Title: "Book Recommendation"
Course ID: "CSDA1040"
Professor: "Mr. Hashmat"
Author: "Group Project: Aimin Amy Hu, Jacob Geeves, Eugene Park"
Date: '2019-May-26'
output:
  html_document: 
    self_contained: no
  pdf_document: default
---



## Getting started
To work with R Markdown, if necessary:

* Install [R](http://www.r-project.org/)
* Install the lastest version of [RStudio](http://rstudio.org/download/) (at time of posting, this is 0.96)
* Install the latest version of the `knitr` package: `install.packages("knitr")`

To run the basic working example that produced this blog post:

* Open R Studio, and go to File - New - R Markdown
* If necessary install `ggplot2` and `lattice` packages: `install.packages("ggplot2"); install.packages("lattice") `
* Paste in the contents of this gist (which contains the R Markdown file used to produce this post) and save the file with an `.rmd` extension
* Please also install.package("pROC")
* Click Knit HTML


## Abstract

The objective for this project is to builde a book recommender system which could suggest books to users based on similarities between books.In other words, it would recommend books that are similar to ones that a user already likes. It would look into similar books from the same genre(perhaps fantasy, science fiction, romance, thriller, mystery etc.). It can even make recommendation based on any variety of common elements such as from the same author.

## Introduction
With techlogy rapidly update every day, online shopping, social media, YouTube and Netflix and many other websites are becoming  hoter and hoter every day. When you shopping on Amazon, you properly noted there were some products recommendation below the products which you have just bought.Have you ever bought anything from their recommended products? Did the recommended product ratings affect your buying decision? How did the recommend this product to you? Instead of discuss recommendation for shopping items online, we will discuss  recommendation system for books in this report.

## Business Objective
The objective for this project is to builde a book recommender system which could suggest books to users based on similarities between books

### Research Questions:

* Q1: Does book's rating affect book's popularity?
* Q2: How to predict user's rating or preferences for a given book?
* Q3: How variables provide a predictive estimate of the likely ?


## Part 1: Data Understanding

### Data Source

The datasets used in this project is hosted by http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/ and below is the link to the dataset.

https://github.com/zygmuntz/goodbooks-10k/releases

Downloaded dataset and saved in local computer.

We assume the dataset come from a site similar to goodreads.com but with more permissive terms of use.
Use below R code to read CSV files from local computer

```{r results='hide', message=FALSE, warning=FALSE}
#start by loading some libraries
library(recommenderlab)
library(data.table)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(DT)
library(knitr)
library(grid)
library(gridExtra)
library(corrplot)
library(methods)
library(Matrix)
library(reshape2)

```
```{r}
#set up working directory - this will set the working directory to the same folder as your R studio RMD file - ensure that the CSVs outlined below are also in this folder
set_wd <- function() {
library(rstudioapi) # make sure you have it installed
current_path <- getActiveDocumentContext()$path 
setwd(dirname(current_path ))
print( getwd() )
}


# Read 5 CSV files along with header
books=read.csv("books.csv",header = TRUE)
book_tags=read.csv("book_tags.csv", header = TRUE)
ratings= read.csv("ratings.csv", header = TRUE)
tags = read.csv("tags.csv", header = TRUE)
to_read = read.csv("to_read.csv", header =TRUE)

```
```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

### Data Summary

This dataset contains 5 CSV files:book_tags.csv, books.csv, ratings.csv, tags.csv, to_read.csv. We used R read.csv command to read all csv files into data frame.


######to_read:
Contains 912705 observations(rows) and 2 variables(columns). This data set contains user_id and book_id.

```{r}
glimpse(to_read)
```

#### ratings.csv
Contains 5976479 observations(rows) and 3 variables(columns). This data set includes all users's ratings of the 10,000 books.

```{r, result='asis', echo=FALSE}
datatable(head(ratings, 10), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(ratings)
```

#### books.csv
Contains 10000 observations(rows) and 23 variables(columns). This data set contains more information on the books such as author, original_publcation_year, rating,book_id etc.

```{r, result='asis', echo=FALSE,message=FALSE, warning=FALSE}
datatable(head(books,5),  class = "nowrap hover row-border", options = list(dom = 't',scrollX = TRUE, autoWidth=TRUE, columnDefs = list(list(width = '100px', targets = c(6)),list(width = '100px', targets = c(5,6)))))
```
<br>
```{r, echo=FALSE}
glimpse(books)
```

#### book_tags.csv
Contains 999912 observations(rows) and 3 variables(columns). This data set has all tag_ids users have assigned to that books and corresponding tag_counts.

```{r, result='asis', echo=FALSE}
datatable(head(book_tags, 10), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(book_tags)
```

#### tags.csv
Contains 34252 observations(rows) and 2 variables(columns). This data set includes the tag_names corresponding to the tag_ids

```{r, result='asis', echo=FALSE, warning=FALSE, message=FALSE}
datatable(sample_n(tags, 5), class = "nowrap hover row-border", options = list(dom = 't',scrollX = FALSE, autoWidth = TRUE))
```

<br>
```{r, echo=FALSE}
glimpse(tags)
```

## Part 2: Data Prepartion

To prepare quality dataset for the machine learning, we will need to check our dataset for any duplicated elements, missing values.

### Step 1: Duplicated elements
We will check if there are duplicated elements in ratings dataset and books dataset. Some users may rating same book for twice. If this is a case, we will then remove the duplicated rows. Also, we will make sure there are not duplicated books in the books dataset. To do this, we will use dplyr. We found there are no duplicated rows in books and book_tags datasets.
```{r}
#loading library for identifying duplicated rows.
library(dplyr)
```
```{r}
#checking if there are duplicated rows

ratings <- ratings %>%
              distinct(user_id, book_id, .keep_all = TRUE)
```
```{r}
books <- books %>%
                distinct(book_id, .keep_all = TRUE)
```

### Step 2: Missing Values

Using code: colSums(is.na()) to get below display. This tells which variable has how many missing values in this data set.


```{r}

#checking missing value for the dataset
colSums(is.na(book_tags))

```
```{r}
colSums(is.na(books))

```
```{r}
colSums(is.na(ratings))

```
```{r}
colSums(is.na(tags))

```

```{r}
colSums(is.na(to_read))


```


In summary of above results, the missing values are summarized as below list:

Data set  |Variable name             | Missing/NA Values           
----------|--------------------------|-------------------
  books   | isbn13                   | 585                       
  books   | original_publication_year| 21  
          |                          |
There are only missing vaules in books_df. The missing values are isbn(International Standard Book Number) and original_publication_year. These two variables will not be variables used in a recommender system. Therefore, we will not deal these missing values. We can be confident is saying that this dataset contains good quality data.

### Step 3:Clean data

Before we use the dataset, we will do some data clean to remove unuseful values. In this way, it will make the dataset smaller and make computation faster.

*	Remove variables: books dataset
* This data set contains 585 missing values under variable 'isbn13'. We have variable 'isbn', we assume these two variables are the same, hence, we    will remove variable 'isbn13' from the data frame. 

* This data set contains variable 'best_book_id'. This id number is identical to variable 'goodreads_book_id'. Becasue variable 'goodreads_book_id' is cross referenced in the 'book_tags_df' dataset it will remain while the 'best_book_id' variable is removed.

* This data set contains variable 'work_id'. This variable will be removed as book_id and goodreads_book_id already serve to identify a unique book.


```{r}
books <- select(books, -c("isbn13", "best_book_id"))

```

After removed two variables from this dataset, we are haveing 21 variables.

##Part 3: Data Exploration


### Data Exploration:ratings dataset

####Select a subset dataset
Our ratings dataset contains about 6 million rows, it is huge dataset for the analysis and also takes a lot of memory space. In order to have faster computation speed, we decided to suset the ratings dataset with sample fraction at 25% . As it is huge dataset (still about 1.5million rows), we believe this subset will not bring any bias for the analysis.

```{r}
# with 25% of users(for FYI only, I have tried 40%, it's still very slow for computation of matrix, therefore, we decided to use 25% instead )
set.seed(1)
user_fraction <- 0.25
users <- unique(ratings$user_id)
```

```{r}
sample_users <- sample(users, round(user_fraction * length(users)))
```

```{r}
cat('Number of ratings (before): ', nrow(ratings))
```
```{r}
ratings <- filter(ratings,user_id %in% sample_users)

cat('Number of ratings (after): ', nrow(ratings))
```
As we know that the ratings dataset contains user_id, book_id and rating. We use ggplot() and geom()to get visulaztion between these variables.

#### Distribution of ratings
We check distribution of ratings and found:
The most of ratings are between 3-5 and about 100,000 ratings are in 1 and 2.

```{r}
library(ggplot2)
ratings %>% 
  ggplot(aes(x = rating, fill = factor(rating))) +
  geom_bar(color = "grey10") + scale_fill_brewer(palette = "Dark2") + guides(fill = FALSE)

```


#### Number of ratings per book
We want to check the distribution of the number of ratings for each book. Most of books has total number of ratings below 1000.

```{r}
#group by book_id,then do the plot
ratings %>% 
  group_by(book_id) %>% 
  summarize(number_of_ratings_per_book = n()) %>%
  ggplot(aes(number_of_ratings_per_book)) + 
  geom_bar(fill = "green", color = "grey20",width = 1) +
  coord_cartesian(c(100, 3000))
  
```

####Number of ratings per user
People are pretty active for the ratings. Most of people have number of rating between 75 - 150 times.
```{r}
ratings %>% 
  group_by(user_id) %>% 
  summarize(number_of_ratings_per_user = n()) %>% 
  ggplot(aes(number_of_ratings_per_user)) + 
  geom_bar(fill = "cadetblue3", color = "grey20") + coord_cartesian(c(3, 200))
```

####Distribution of mean book ratings
What we have seen from below plot is the most of books have mean between 3.5- 5, this tells us that most of books get postive ratings.
```{r}
#group by book_id and get mean of rating for each book_id. We get a new dataset with column mean_perbook

rating_perbook<-ratings %>%
        group_by(book_id) %>%
        mutate(mean_perbook = mean(rating, na.rm=T))
        
```

```{r}
ggplot(rating_perbook, aes(mean_perbook))+geom_histogram(fill = "orange", color = "grey20", bins = 30) + coord_cartesian(c(1,5))
```

####Distribution of mean user ratings
From below plot, we saw that more people tend to give ratings higher than 3.5. Some of them have tendence to give highest rating 5, and another concentration area is around rating 4.

```{r}
ratings %>% 
  group_by(user_id) %>% 
  summarize(mean_per_user_rating = mean(rating)) %>% 
  ggplot(aes(mean_per_user_rating)) +
  geom_histogram(fill = "red", color = "grey20", bins =30)
```

####Does rater relate to rating?
From below plot, we see a possiblity of rating differently between frequent users and less frequent users.

```{r, message=FALSE, warning=FALSE}
ratings %>%
  group_by(user_id) %>%
  summarize(mean_rating =mean(rating), number_of_rated_books =n())%>%
  ggplot(aes(number_of_rated_books, mean_rating))+stat_bin_hex(bins =50) +scale_fill_distiller(palette ="Spectral")+
  stat_smooth(method = "lm", color = "orchid", size = 2)+
  scale_color_gradient()+
  theme_bw()

```


### Data Exploration:books dataset

The books dataset contains 21 variables after our data cleaning. We will explore some variables in this dataset to see how they are related to the ratings.

```{r}
# list of varialbe names in the books dataset
names(books)
```
We see there are variables called language_code and authors. First, we will check how laugange related to the books. We uderstood that the dataset is from an English speaking website and assume that the most of books are English.

####Languages

From below plots, we see there are less than 1000 books are non-English.

```{r}
#import some libraries
library(grid)
library(ggplot2)
library(lattice)

```
```{r}
#language: English(this will include en-US, en-GB,eng,en-CA)
p_english <- books %>% 
  mutate(language = factor(language_code)) %>% 
  group_by(language) %>% 
  summarize(number_of_books = n()) %>% 
  arrange(-number_of_books) %>% 
  ggplot(aes(reorder(language, number_of_books), number_of_books, fill = reorder(language, number_of_books))) +
  geom_bar(stat = "identity", color = "grey20", size = 0.5) + coord_flip() +
  labs(x = "language", title = "English") + guides(fill = FALSE)

P_non_english <- books %>% 
  mutate(language = factor(language_code)) %>% 
  filter(!language %in% c("en-US", "en-GB", "eng", "en-CA", "")) %>% 
  group_by(language) %>% 
  summarize(number_of_books = n()) %>% 
  arrange(-number_of_books) %>% 
  ggplot(aes(reorder(language, number_of_books), number_of_books, fill = reorder(language, number_of_books))) +
  geom_bar(stat = "identity", color = "grey20", size = 0.5) + coord_flip() +
  labs(x = "", title = "Non-English") + guides(fill = FALSE)

grid.arrange(p_english,P_non_english, ncol=2)

```


####Authors
We see from below plot, there are a few authors with lower rating below 3,which may indicate that rating is high or low not related to authors.
```{r}
books %>% 
  group_by(authors, average_rating) %>% 
  summarize(mean_per_authors_rating = mean(average_rating)) %>% 
  ggplot(aes(mean_per_authors_rating)) +
  geom_histogram(fill = "red", color = "grey20", bins =30)

```


However,we saw number of authors is a matter of the rating from below plot.The more authors a book has the higher average rating is. 

```{r}
books_author <- books %>% 
  group_by(book_id) %>% 
  mutate(number_of_authors = length(str_split(authors, ",")[[1]]))

books_author %>% filter(number_of_authors <= 10) %>% 
  ggplot(aes(number_of_authors, average_rating)) + stat_bin_hex(bins = 50) + scale_fill_distiller(palette = "Spectral") +
  stat_smooth(method = "lm", size = 2, color = "orchid", se = FALSE)+
  scale_color_gradient()+
  theme_bw()

```


#### Does average_rating relate to ratings_count?
From below plot, we see there are only in a small extent, average_rating is higher and number of ratings_count is higher.

```{r}
ggplot(books,aes(x=ratings_count, y=average_rating))+
  geom_point(aes(color = books_count)) +
  stat_smooth(method = "lm", color = "orchid", size = 2)+
  scale_color_gradient()+
  theme_bw()
  
       
```


#### Top 10 books in average_rating  
We rank the top 10 rated books according to their average_rating. The Complete Calvin and Hobbes has the highest average_rating at 4.82, it's so close to 5. With 28900 ratings_count, we see almose every one gives this book high rating.  
```{r}
#import library
library(DT)
library(dplyr)
```
```{r}
#use arrange()to sort variable avaerage_rating, then get the top 10 books with title, ratings_count, average_rating and authors
  books %>% 
  arrange(-average_rating) %>% 
  top_n(10,wt = average_rating) %>% 
  select(title, ratings_count, average_rating, authors) %>% 
  datatable(class = "nowrap hover row-border", escape = FALSE, options = list(dom = 't',scrollX = TRUE, autoWidth = TRUE))

```


#### Top 10 books in ratings_count  
We rank the top 10 books according to their ratings_count. We saw some books on the list but their average_rating is less than mean of average_rating. This tells us a book is popular to be rated, but it doesn't mean that this book has higher average_rating.


```{r}
#use arrange()to sort variable ratings_count, then get the top 10 books with title, ratings_count, average_rating and authors
  books %>% 
  arrange(-ratings_count) %>% 
  top_n(10,wt = ratings_count) %>% 
  select(title, ratings_count, average_rating, authors) %>% 
  datatable(class = "nowrap hover row-border", escape = FALSE, options = list(dom = 't',scrollX = TRUE, autoWidth = TRUE))
```
```{r}
# mean of average_rating
mean(books$average_rating)
```

### Correlation Matrix

A correlation matrix is a table showing correlation coefficients between variables. The books contains many variables. Some of variables may not have correlation or weak correlation with other variables. Use corrplot() function to see Visualization of Correlation Matrix.

We see some correlations from below correlation martrix plot.

* Variable ratings_count has positive 1 correlation with variable work_ratings_count. Does this mean that they are same vaules but just called different variable name? We are not sure about this as the discrepation about the dataset did not specify it.

* Variable work_text_reviews_count has positive 0.8 correlation with ratings_count and work_ratings_count.This total make sense, when people read text review, will more likely to rate it.

* Variable books_count has positive correlation with variable work_text_reviews_count, ratings_count and work_ratings_count; this variable also has strong negative correlation with variable original_publication_year, this does make sense as the original_publication_year increases, the books_count decreases. Variable books_count also has negative correlation with average_rating, but not strong, is just about -0.1.


```{r}
#correlation matrix, select variables with numeric vaules
books_subset <- books %>% 
  select(one_of(c("books_count","original_publication_year","ratings_count", "work_ratings_count", "work_text_reviews_count", "average_rating"))) %>% 
  as.matrix()
corrplot(cor(books_subset,use = 'pairwise.complete.obs'), type = "upper", order = "hclust")
        
```


###Conclusion
We have explored ratings dataset and books dataset and identified some variables that affect on book ratings, this will help us to recommend a book. However,these dataset does not include many other aspects such as user's age group, income, education, culture backgroud etc. We are unclear how these aspects influnce on the book ratings.


## Part 4: Build Model - Collaborative Filtering

Collaborative filtering is a method that uses data from other users to make its prediction. 

A recommendation system is a type of information filter, which can learn users’ interests and hobbies according to their profile or historical behaviors, and then predict their ratings or preferences for a given item. Recommendation algorithms generally make recommendations based on two types of collaborative filtering algorithms; User-based collaborative or item-based collaborative filtering. 

**User-based collaborative filtering systems**: A user-based recommendation engine recommends products such as movies or online shopping items, books based on what other users with similar profiles have watched/liked or bought in the past. 


**Item-based collaborative filtering systems**: An item-based recommender would make recommendations based on similarities bewtween products. It would recommend the products that are similar to ones that you already like. For example, if a user readed  "Little Women" and liked it so this user given it rating 5 stars. A item-based collaborative filtering system would then look into similar books from the same genre(perhaps romance,true love, womenhood or based on similar storyline) and then recommend to the user similar books based on the preference the user indicated when he/she gave "Little Women" rating. An item-based collaborative filtering system can also make recommendations based on any other variety of common elements such as from the same author.

In this project, we will implement User-based collaborative filtering systems. Below are steps for useing Recommenderlab in R.


###Step 1: Create ratings matrix

######Create a sample matrix for understanding

To restructure our train dataset by create a ratings matrix with rows as user_id and columns as book_id. Here is example to understand it.
user_id: 6,7,8
book_id:1,2,3,4,5

```{r, echo=FALSE}
#Create ratings matrix with rows as user_id and columns as book_id.
matrix(data = c(NA, 5, 4, NA, NA, 2, 1, NA, 4, NA, NA, NA, 3, NA, 3), nrow = 3, ncol = 5, byrow = TRUE, dimnames = list(user_id = 6:8, book_id = 1:5))

```

######Create ratings dataset matrix with rows as user_id and columns as book_id

```{r}
#creat a dimension_names list
dimension_names <- list(user_id = sort(unique(ratings$user_id)), book_id = sort(unique(ratings$book_id)))
```

```{r, message = FALSE,warning=FALSE}
library(tidyverse)

```

```{r}
#Spread a key-value pair across multiple columns.spread() takes two columns (key & value), and spreads into multiple columns: it makes “long” data wider.(will take several minutes due to the large dataset)
ratingmat <- spread(select(ratings, book_id, user_id, rating), book_id, rating) %>%
  select(-user_id)
    
```
```{r}
#Create train dataset matrix with rows as user_id and columns as book_id

ratingmat = as.matrix(ratingmat)
```

```{r}
# check the class ratingmat
class(ratingmat)

```

```{r}
#set the dimnames of matrix
dimnames(ratingmat)<-dimension_names
ratingmat[1:5, 1:5]
```
```{r}
#check dimension of ratingmat matrix
dim(ratingmat)

```


###Step 2:Covert ratings matrix to real matrix

In above, we see there are the most of the values in the rating matrix are missing(null values), because every user just rated a few of the 10000 books. We will replace the null values with "0" in the matrix, this allows us to represent this matrix as "sparse matrix".


```{r}
# save ratingmat to a new dataset and replacing null values dataset with 0(will take several minutes)
ratingmat_new <- ratingmat
ratingmat_new[is.na(ratingmat)] <- 0

#sparseMatrix
sparse_ratings <- as(ratingmat_new, "sparseMatrix")

```


Conver ratings matrix into a dense matrix by removing the zero's

```{r}
#Convert ratings matrix into real matrix which makes it dense.
real_ratings =new("realRatingMatrix", data=sparse_ratings)

```



###Step 4: Useing Recommenderlab
The recommendation package in R that we will use is recommenderlab. It provides us a User Based Collaborative Filtering (UBCF) model. For similarity among user ratings, we have a choice to calculate similarity according to the following methods:

* Jaccard similarity
* Cosine similarity
* Pearson similarity

###### Create Recommender Model.
The parameters are UBCF and Cosine similarity. We take 5 nearest neighbours.

```{r}

#Create Recommender Model. The parameters are UBCF and "cosine" similarity. We take 5 nearest neighbours
rec_mod = Recommender(real_ratings, method = "UBCF", param=list(method="cosine",nn=5)) 

```
###### Predictions
We have built our model, now we can start to do predictions by call predict(). This will pass the model, the ratings for the user that you wish to predict ratings for and a parameter which is to tell the function that you want to get predicted ratings back.

Let's predict the 20th user entry in the real_ratings dataset.We want to look at the top 5 recommendations for the 20th user entry in the dataset. For the convenience, we call this user "Galileo"
```{r}
#Obtain top 5 recommendations for 20th user(Galileo) entry in dataset
Top_5_pred = predict(rec_mod, real_ratings[20], type="ratings")

# Convert the list to data frame

Top_5_df =as(Top_5_pred, "data.frame")
```

```{r}
head(Top_5_df)
```

```{r, message=FALSE, warning=FALSE}
# arrange by rating and left_join with books dataset to get book title, author and book_id
Top_5_df %>%
  arrange(-rating) %>% .[1:5,] %>%
  mutate(book_id = as.numeric(as.character(item))) %>%
  left_join(select(books,authors,title, book_id),by ="book_id") %>%
  select(-item) %>%
  datatable(class = "nowrap hover row-border",escape=FALSE, options = list(dom = 't',scrollx = TRUE, autoWidth = TRUE))

```
Based on similarity between users, our model recommends above 5 books to "Galileo".

###Step 5: Evaluating The Predictions

######create evaluation scheme
Recommenderlab offers the possibility to easily evaluate and compare algorithms for recommendation systems.
evaluationScheme() is to create an evaluationScheme object from a data set. The scheme can be a simple split into training and test data, k-fold cross-evaluation or using k independent bootstrap samples.
method: cross-validation
k: 1 fold crossvalidation
given = -1:means all-but-1 evaluation
goodRating = 4: all items with actual user rating of greater or equal 4 are considered positives in the evaluation process.



```{r}
# Let's check some algorithms against each other.(I tried to use "split" with train = .6, it takes so long time to run on the evaluate()function, therefore, I am using the "cross-validation")
scheme <- evaluationScheme(real_ratings[1:600,], method = "cross-validation", k = 10, given = -1, goodRating = 4)

```
###### List all the Algorithms 
We can list all the algorithms we want to compare.
nn: the number of most similar users which are used to calculate the predictions
algorithm ="RANDOM": randomly predicts a rating for each user

```{r}
algorithms <- list("random" = list(name = "RANDOM", param = NULL),
                   "UBCF_5" = list(name = "UBCF", param = list(nn = 5)),
                   "UBCF_10" = list(name = "UBCF", param = list(nn = 10)),
                   "UBCF_20" = list(name = "UBCF", param = list(nn = 20)),                 
                   "UBCF_40" = list(name = "UBCF", param = list(nn = 40))
                   )
```
######Evaluate all results
We use evaluate() function to evaluate the alogrithms with the given scheme. Let's predict it.

```{r}
# run alogrithms and predict
eva_results <- evaluate(scheme, algorithms,type ="ratings")
```

######Plot RMSE,MSE and MAE for eva_results

* RMSE: Root Mean Square Error. It tells you how concentrated the data is around the line of best fit.
In order to plot RMSE, we will need to re-structure eva_results.

* MSE: Mean Squared Error. MSE puts more weight into penalizing larger errors, so MSE is more useful when large errors are undesirable.

* MAE: Mean Absolute Error.It is a measure of deviation of recommendation from user’s actual value.

```{r}

plot(eva_results)

```
The lower the MAE and RMSE, the more accurately the recommendation engine predicts user ratings. These metrics are good to use when the recommendations are based on predicting rating or number of transactions. They give us a sense of how accurate our prediction ratings are, and in turn how accurate our recommendations are.

In above, we see user_based CF algrothms preform better prediction than random. There is no change on predictions with increasing number of nearest neighbours nn.

######Different Algorithms
Now, we want to compare the performace of different algorithms. The following algorithms are available in Recommenderlab.

```{r}
recommenderRegistry$get_entry_names()

```
We will compare UBCF with two additional algorithms, “popular” predicts ratings accoring to their mean_rating, SVD is matrix factorization approach(tried to use IBCF, but it took too long time to run the alogrithm, therefore, changed to SVD instead).

```{r}
# create scheme
scheme_2 <- evaluationScheme(real_ratings[1:600,], method = "cross-validation", k = 10, given = -1, goodRating = 4)

```
```{r}
#different algorithms (I was trying to use IBCF, however, it took too long time for predict and decide to use)
algorithms_2 <- list("random" = list(name = "RANDOM", param = NULL),
                   "popular" = list(name = "POPULAR"),
                   "UBCF" = list(name = "UBCF"),
                   "SVD" = list(name = "SVD")
                   )
```
```{r}
#run alogrithms and predict               
eva_results_2 <- evaluate(scheme_2, algorithms_2, type = "ratings")

```
```{r}
head(eva_results_2)
```
Plot RMSE,MSE and MAE for eva_results_2

```{r}
plot(eva_results_2)
```

#This is as of May 23 at 6:20
#Shiny App is on pending