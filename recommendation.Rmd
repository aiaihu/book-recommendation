
---
Title: "Book Recommendation"
Course ID: "CSDA1040"
Professor: "Mr. Hashmat"
Author: "Group Project: Aimin Amy Hu, Jacob Geeves"
Date: '2019-May-26'
output:
  html_document: 
    self_contained: no
  pdf_document: default
---



## Getting started
To work with R Markdown, if necessary:

* Install [R](http://www.r-project.org/)
* Install the lastest version of [RStudio](http://rstudio.org/download/) (at time of posting, this is 0.96)
* Install the latest version of the `knitr` package: `install.packages("knitr")`

To run the basic working example that produced this blog post:

* Open R Studio, and go to File - New - R Markdown
* If necessary install `ggplot2` and `lattice` packages: `install.packages("ggplot2"); install.packages("lattice") `
* Paste in the contents of this gist (which contains the R Markdown file used to produce this post) and save the file with an `.rmd` extension
* Please also install.package("pROC")
* Click Knit HTML


## Abstract

The objective for this project is to builde a book recommender system which could suggest books to users based on similarities between books.In other words, it would recommend books that are similar to ones that a user already likes. It would look into similar books from the same genre(perhaps fantasy, science fiction, romance, thriller, mystery etc.). It can even make recommendation based on any variety of common elements such as from the same author.

## Introduction



## Business Objective
The objective for this project is to builde a book recommender system which could suggest books to users based on similarities between books



## Part 1: Data Understanding

### Data Source

The datasets used in this project is hosted by http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/ and below is the link to the dataset.

https://github.com/zygmuntz/goodbooks-10k/releases

Downloaded dataset and saved in local computer.

We assume the dataset come from a site similar to goodreads.com but with more permissive terms of use.
Use below R code to read CSV files from local computer

```{r}
#start by loading some libraries
library(recommenderlab)
library(data.table)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(DT)
library(knitr)
library(grid)
library(gridExtra)
library(corrplot)
library(methods)
library(Matrix)
library(reshape2)

```
```{r}
#set up working directory
setwd("~/York U School/CSDA1040/Project_1/Datasets")

# Read 5 CSV files along with header
books=read.csv("books.csv",header = TRUE)
book_tags=read.csv("book_tags.csv", header = TRUE)
ratings= read.csv("ratings.csv", header = TRUE)
tags = read.csv("tags.csv", header = TRUE)
to_read = read.csv("to_read.csv", header =TRUE)

```

## Data Summary

This dataset contains 5 CSV files:book_tags.csv, books.csv, ratings.csv, tags.csv, to_read.csv. We used R read.csv command to read all csv files into data frame.
```{r, eval=FALSE,echo=FALSE}

#check data frame details
str(book_tags)
str(books)
str(ratings)
str(tags)
str(to_read)

```

######books:
Contains 10000 observations(rows) and 23 variables(columns). This data set contains more information on the books such as author, original_publcation_year, rating,book_id etc.

######book_tags:
Contains 999912 observations(rows) and 3 variables(columns). This data set has all tag_ids users have assigned to that books and corresponding tag_counts.

######rating:
Contains 5976479 observations(rows) and 3 variables(columns). This data set includes all users's ratings of the books.

######tags:
Contains 34252 observations(rows) and 2 variables(columns). This data set includes the tag_names corresponding to the tag_ids

######to_read:
Contains 912705 observations(rows) and 2 variables(columns). This data set contains user_id and book_id.

###Use head()command to show first 6 rows of each data frame

```{r, echo=FALSE}

#show first 6 rows of book_tags_df
head(book_tags)

```
```{r, echo=FALSE}
#show first 6 rows of books_df
head(books)

```
```{r,echo=FALSE}
#show first 6 rows of ratings_df
head(ratings)

```
```{r, echo=FALSE}
#show first 6 rows of tags_df
head(tags)

```
```{r, echo=FALSE}
#show first 6 rows of to_read_df
head(to_read)
```


## Data Exploration

### Missing Values

Using code: colSums(is.na()) to get below display. This tells which variable has how many missing values in this data frame.


```{r}

#checking missing value for the dataset
colSums(is.na(book_tags))

```
```{r}
colSums(is.na(books))

```
```{r}
colSums(is.na(ratings))

```
```{r}
colSums(is.na(tags))

```

```{r}
colSums(is.na(to_read))


```
In summary of above table, the missing values are summarized as below list:


Variable name             | Missing/NA Values           
------------------------- | ------------------
isbn13                    | 585                       
original_publication_year | 21  

There are only missing vaules in books_df. The missing valuse are isbn(International Standard Book Number) and original_publication_year. These two variables will not be variables for recommender system. Therefore, we will not deal thse missing values. We are confident to say this dataset has good quality of data.
There are only missing vaules in books_df. The missing values are isbn(International Standard Book Number) and original_publication_year. These two variables will not be variables used in a recommender system. Therefore, we will not deal these missing values. We can be confident is saying that this dataset contains good quality data.

##Part 2: Data Preparation

### Clean data

Before we use the books dataset, we will do some data clean to remove unuseful values. In this way, it will make the dataset smaller and make computation faster.

  *	This data frame contains 585 missing value in variable "isbn13". We have variable "isbn", we assume these two variables are same, hence, we will remove variable"isbn13"from the data frame. 
  *On this data set, it als contains a variable called: best_book_id. This id number is same as variable: goodreads_book_id. We will keep goodreads_book_id as this variable is also corresponding in book_tags_df dataset, but will remove best_book_id variable.
  * work_id on this data set will be removed as we have book_id and goodreads_book_id to indicate a unique book.

```{r}
#check if there are dupicatie elements in datasets
tags[duplicated(tags)]
```
```{r}

#Create ratings matrix with rows as users and columns as books. 
ratingmat = dcast(ratings, user_id~book_id, value.var = "rating", na.rm=FALSE)
```
```{r}
# check the class ratingmat
class(ratingmat)

```
```{r}
# remove user_id as we don't need it
ratingmat = as.matrix(ratingmat[,-1])
```

```{r}
#Convert ratings matrix to real rating matrx which makes it dense
ratingmat = as(ratingmat,"realRatingMatrix")

```
By running above code, we reduced the size of ratingmat file to 69mb


### Normalize the matrix
```{r}
ratingmat_n =normalize(ratingmat)


```

###Create Recommender Model. The parameters are UBCF and Cosine similarity. We take 10 nearest neighbours
```{r}
rec_mod = Recommender(ratingmat_n,method = "UBCF",param =list(method ="Cosine",nn=10))
```
### Obtain top 5 recommendations for 1st user entry in dataset
```{r}
Top_5_pred = predict(rec_mod, ratingmat_n[1],n=5)

```
```{r}
#convert the recommendations to a list
Top_5_list = as(Top_5_pred, "list")
Top_5_list
```
We got book recommendations for the top 5 books, but they are in book_id number format. Now, we need to look at the book names that correspond to these book_id number.We will do this by using the books dataset. It maps book_id to book tiles.


  
```{r}
# Part 2: Data Preparation

# clean the data

```
  